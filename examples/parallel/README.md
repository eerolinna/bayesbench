# Running inferences in parallel

This example runs inferences for all models, methods and diagnostics in a specified knowledge base.
`generate_arguments.py` is used to generate list of jobs, `run.py` is used to run a job and `view.py` is for viewing result of the jobs.

## Misc

We assume that all methods in the knowledge base have a corresponding implementation.

Are existing outputs cached?

SBC is missing
